{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qNig_zo9gTOM"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "def create_pipeline(numerical_features, categorical_features):\n",
        "    # Create pipeline for preprocessing numerical features\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
        "        ('scaler', StandardScaler()),  # Scale numerical features\n",
        "        ('selector', SelectKBest(k='all'))  # Select features\n",
        "    ])\n",
        "\n",
        "    # Create pipeline for preprocessing categorical features\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing pipelines\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create full pipeline including preprocessing and model training\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', DecisionTreeClassifier())  # Use DecisionTreeClassifier\n",
        "    ])\n",
        "\n",
        "    return full_pipeline\n",
        "\n",
        "def ratio(array):\n",
        "  class_counts = array.value_counts()  # Count occurrences of each class\n",
        "  total_samples = class_counts.sum()  # Total number of samples in the dataset\n",
        "\n",
        "  # Calculate percentages for each class\n",
        "  percentage_0 = (class_counts[0] / total_samples) * 100\n",
        "  percentage_1 = (class_counts[1] / total_samples) * 100\n",
        "\n",
        "  return (\"Percentage of class '0': {:.2f}%\".format(percentage_0)),(\"Percentage of class '1': {:.2f}%\".format(percentage_1))\n",
        "\n",
        "def genpipeline(array):\n",
        "  pipe = Pipeline(steps=['ratio', ratio(array)])\n",
        "  return pipe\n",
        "# Example usage:\n",
        "# Define categorical and numerical features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/heart.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThDUasW9kyQ5",
        "outputId": "a964e2f7-36df-46e1-e600-b496114a3d81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0      52    1   0       125   212    0        1      168      0      1.0   \n",
            "1      53    1   0       140   203    1        0      155      1      3.1   \n",
            "2      70    1   0       145   174    0        1      125      1      2.6   \n",
            "3      61    1   0       148   203    0        1      161      0      0.0   \n",
            "4      62    0   0       138   294    1        1      106      0      1.9   \n",
            "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
            "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
            "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
            "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
            "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
            "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
            "\n",
            "      slope  ca  thal  target  \n",
            "0         2   2     3       0  \n",
            "1         0   0     3       0  \n",
            "2         0   0     3       0  \n",
            "3         2   1     3       0  \n",
            "4         1   3     2       0  \n",
            "...     ...  ..   ...     ...  \n",
            "1020      2   0     2       1  \n",
            "1021      1   1     3       0  \n",
            "1022      1   1     2       0  \n",
            "1023      2   0     2       1  \n",
            "1024      1   1     3       0  \n",
            "\n",
            "[1025 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(columns=['target'])  # Features\n",
        "y = df['target']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets to verify the split\n",
        "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlPH6aJZlTk4",
        "outputId": "54800cc4-b983-43f9-9280-18910cacb014"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (820, 13) (820,)\n",
            "Testing data shape: (205, 13) (205,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "val = create_pipeline(numerical_features,categorical_features)"
      ],
      "metadata": {
        "id": "ccFbju30pBGV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val.fit(X_train,y_train)\n",
        "accu = val.predict(X_test)\n",
        "print(accu)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35zfSIA2pcTQ",
        "outputId": "cb536a2e-33e6-4fea-8a57-a73b0819d52a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
            " 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = genpipeline(pd.DataFrame(accu))\n",
        "print(gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "him7aBF-t3LQ",
        "outputId": "2c31f7fc-c533-4870-90dc-d4e7dec2bf06"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=['ratio',\n",
            "                (\"Percentage of class '0': 51.22%\",\n",
            "                 \"Percentage of class '1': 48.78%\")])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = val.score(X_test,y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVfX40fwprMy",
        "outputId": "6ee5d799-42fa-401c-a69f-6f2e6f557b7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9853658536585366\n"
          ]
        }
      ]
    }
  ]
}